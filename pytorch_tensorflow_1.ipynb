{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMJreAepvJ09vuAwkIuWDkU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushjaiswal21/-90DayML/blob/main/pytorch_tensorflow_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1rLlxHSp6GU6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pprint # For pretty printing large outputs if needed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Initializing Tensors ---\n",
        "\n",
        "print(\"--- 2. Initializing Tensors ---\")\n",
        "\n",
        "# 2.1. From Python List / NumPy Array\n",
        "print(\"2.1. From Python List / NumPy Array:\")\n",
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)\n",
        "print(f\"Tensor from list:\\n{x_data}\")\n",
        "\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)\n",
        "print(f\"Tensor from NumPy array:\\n{x_np}\")\n",
        "print(f\"Data type of x_np: {x_np.dtype}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwAwNZ5E6itK",
        "outputId": "593b9813-41cb-43ba-ddee-34e6b15a30e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 2. Initializing Tensors ---\n",
            "2.1. From Python List / NumPy Array:\n",
            "Tensor from list:\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "Tensor from NumPy array:\n",
            "tensor([[1, 2],\n",
            "        [3, 4]])\n",
            "Data type of x_np: torch.int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "    print(f\"GPU is available! Using device: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "    print(\"GPU not available. Using CPU.\")\n",
        "\n",
        "print(f\"All tensors will be created on: {device}\\n\")-"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPTD5WcU65jm",
        "outputId": "5ac77a5c-fc4b-40e1-fa49-4da4c6c3f499"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available! Using device: Tesla T4\n",
            "All tensors will be created on: cuda\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2. With specific values / shapes\n",
        "print(\"2.2. With specific values / shapes:\")\n",
        "x_ones = torch.ones(2, 3) # 2 rows, 3 columns, filled with ones\n",
        "print(f\"Tensor of ones (2x3):\\n{x_ones}\")\n",
        "\n",
        "x_zeros = torch.zeros(3, 2) # 3 rows, 2 columns, filled with zeros\n",
        "print(f\"Tensor of zeros (3x2):\\n{x_zeros}\")\n",
        "\n",
        "x_rand = torch.rand(2, 2) # 2x2 tensor with random values from a uniform distribution [0, 1)\n",
        "print(f\"Tensor of randoms (2x2):\\n{x_rand}\")\n",
        "\n",
        "x_randn = torch.randn(2, 2) # 2x2 tensor with random values from a standard normal distribution (mean=0, std=1)\n",
        "print(f\"Tensor of random normal (2x2):\\n{x_randn}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12UGCcPn6iwl",
        "outputId": "dedb4750-53f2-4838-8182-8cd52c744f40"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2. With specific values / shapes:\n",
            "Tensor of ones (2x3):\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "Tensor of zeros (3x2):\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "Tensor of randoms (2x2):\n",
            "tensor([[0.3207, 0.2790],\n",
            "        [0.2799, 0.9726]])\n",
            "Tensor of random normal (2x2):\n",
            "tensor([[ 0.5428,  0.7513],\n",
            "        [-0.7481, -0.9388]])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.3. Like existing tensors (retains properties like shape, dtype, device)\n",
        "print(\"2.3. Like existing tensors:\")\n",
        "x_data_on_device = x_data.to(device) # Move x_data to the selected device\n",
        "\n",
        "x_ones_like = torch.ones_like(x_data_on_device) # Creates a tensor of ones with the same properties as x_data_on_device\n",
        "print(f\"Tensor of ones like x_data_on_device:\\n{x_ones_like}\")\n",
        "print(f\"Device of x_ones_like: {x_ones_like.device}\\n\")\n",
        "\n",
        "x_rand_like = torch.rand_like(x_data_on_device, dtype=torch.float) # Can also override properties\n",
        "print(f\"Tensor of randoms like x_data_on_device (float):\\n{x_rand_like}\")\n",
        "print(f\"Data type of x_rand_like: {x_rand_like.dtype}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR4S2zuc6iz0",
        "outputId": "7fa97cba-8f13-4a19-b8cc-876bf6173caf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3. Like existing tensors:\n",
            "Tensor of ones like x_data_on_device:\n",
            "tensor([[1, 1],\n",
            "        [1, 1]], device='cuda:0')\n",
            "Device of x_ones_like: cuda:0\n",
            "\n",
            "Tensor of randoms like x_data_on_device (float):\n",
            "tensor([[0.8094, 0.1379],\n",
            "        [0.1031, 0.1268]], device='cuda:0')\n",
            "Data type of x_rand_like: torch.float32\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- 3. Tensor Attributes ---\")\n",
        "\n",
        "tensor = torch.rand(3, 4)\n",
        "print(f\"Original tensor:\\n{tensor}\")\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Data type of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\\n\")\n",
        "\n",
        "# Move the tensor to GPU if available and observe device change\n",
        "if device == \"cuda\":\n",
        "    tensor_gpu = tensor.to(\"cuda\")\n",
        "    print(f\"Tensor moved to GPU:\\n{tensor_gpu}\")\n",
        "    print(f\"Device tensor_gpu is stored on: {tensor_gpu.device}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaeLhZwa6i20",
        "outputId": "474fcffb-15f6-4767-9a1d-23360fcf4f8b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 3. Tensor Attributes ---\n",
            "Original tensor:\n",
            "tensor([[0.3210, 0.1393, 0.7949, 0.3036],\n",
            "        [0.9314, 0.1329, 0.0200, 0.5702],\n",
            "        [0.4257, 0.0844, 0.7843, 0.9357]])\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Data type of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n",
            "\n",
            "Tensor moved to GPU:\n",
            "tensor([[0.3210, 0.1393, 0.7949, 0.3036],\n",
            "        [0.9314, 0.1329, 0.0200, 0.5702],\n",
            "        [0.4257, 0.0844, 0.7843, 0.9357]], device='cuda:0')\n",
            "Device tensor_gpu is stored on: cuda:0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Operations on Tensors ---\n",
        "\n",
        "print(\"--- 4. Operations on Tensors ---\")\n",
        "\n",
        "# Ensure tensors are on the same device for operations\n",
        "tensor_a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32).to(device)\n",
        "tensor_b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32).to(device)\n",
        "\n",
        "print(f\"Tensor A:\\n{tensor_a}\")\n",
        "print(f\"Tensor B:\\n{tensor_b}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eq0JKE26i6G",
        "outputId": "e6f286a4-831e-449c-832b-d7eff99f4e25"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 4. Operations on Tensors ---\n",
            "Tensor A:\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]], device='cuda:0')\n",
            "Tensor B:\n",
            "tensor([[5., 6.],\n",
            "        [7., 8.]], device='cuda:0')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 4.1. Arithmetic Operations\n",
        "print(\"4.1. Arithmetic Operations:\")\n",
        "print(f\"Addition (A + B):\\n{tensor_a + tensor_b}\")\n",
        "print(f\"Addition (torch.add(A, B)):\\n{torch.add(tensor_a, tensor_b)}\")\n",
        "print(f\"Subtraction (A - B):\\n{tensor_a - tensor_b}\")\n",
        "print(f\"Multiplication (element-wise A * B):\\n{tensor_a * tensor_b}\")\n",
        "print(f\"Division (element-wise A / B):\\n{tensor_a / tensor_b}\")\n",
        "print(f\"Exponentiation (A**2):\\n{tensor_a**2}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNcEqCzr7Ip8",
        "outputId": "eee80de0-fa33-488c-f422-22593661c635"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.1. Arithmetic Operations:\n",
            "Addition (A + B):\n",
            "tensor([[ 6.,  8.],\n",
            "        [10., 12.]], device='cuda:0')\n",
            "Addition (torch.add(A, B)):\n",
            "tensor([[ 6.,  8.],\n",
            "        [10., 12.]], device='cuda:0')\n",
            "Subtraction (A - B):\n",
            "tensor([[-4., -4.],\n",
            "        [-4., -4.]], device='cuda:0')\n",
            "Multiplication (element-wise A * B):\n",
            "tensor([[ 5., 12.],\n",
            "        [21., 32.]], device='cuda:0')\n",
            "Division (element-wise A / B):\n",
            "tensor([[0.2000, 0.3333],\n",
            "        [0.4286, 0.5000]], device='cuda:0')\n",
            "Exponentiation (A**2):\n",
            "tensor([[ 1.,  4.],\n",
            "        [ 9., 16.]], device='cuda:0')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.2. Matrix Multiplication\n",
        "print(\"4.2. Matrix Multiplication:\")\n",
        "matrix_a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32).to(device) # 2x2\n",
        "matrix_b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32).to(device) # 2x2\n",
        "# Both methods produce the same result for matrix multiplication\n",
        "print(f\"Matrix multiplication (A @ B):\\n{matrix_a @ matrix_b}\")\n",
        "print(f\"Matrix multiplication (torch.matmul(A, B)):\\n{torch.matmul(matrix_a, matrix_b)}\\n\")\n",
        "\n",
        "# Example with different shapes (requires valid matrix multiplication rules)\n",
        "# (1x2) @ (2x3) -> (1x3)\n",
        "vec_a = torch.tensor([1, 2], dtype=torch.float32).to(device) # 1D tensor is treated as 1xN or Nx1 for matmul\n",
        "matrix_c = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32).to(device) # 2x3\n",
        "\n",
        "# For 1D tensors, torch.matmul implicitly adds dimensions.\n",
        "# It's safer to explicitly reshape if unsure.\n",
        "# Here, vec_a is treated as (1, 2)\n",
        "result_matmul = torch.matmul(vec_a, matrix_c)\n",
        "print(f\"Vector (1x2) @ Matrix (2x3):\\n{result_matmul}\")\n",
        "print(f\"Shape of result: {result_matmul.shape}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kpcXOx07Is7",
        "outputId": "01385b12-d4f6-4b52-ea5f-4fbd1200b377"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.2. Matrix Multiplication:\n",
            "Matrix multiplication (A @ B):\n",
            "tensor([[19., 22.],\n",
            "        [43., 50.]], device='cuda:0')\n",
            "Matrix multiplication (torch.matmul(A, B)):\n",
            "tensor([[19., 22.],\n",
            "        [43., 50.]], device='cuda:0')\n",
            "\n",
            "Vector (1x2) @ Matrix (2x3):\n",
            "tensor([ 9., 12., 15.], device='cuda:0')\n",
            "Shape of result: torch.Size([3])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.3. In-place Operations (modify the tensor without creating a new one)\n",
        "print(\"4.3. In-place Operations:\")\n",
        "tensor_inplace = torch.ones(2, 2).to(device)\n",
        "print(f\"Original tensor_inplace:\\n{tensor_inplace}\")\n",
        "tensor_inplace.add_(5) # Note the underscore! This modifies tensor_inplace directly.\n",
        "print(f\"tensor_inplace after add_(5):\\n{tensor_inplace}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6zWY1_B7Iv1",
        "outputId": "419a7d1d-6d77-4ecf-b501-821efe0cfa79"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.3. In-place Operations:\n",
            "Original tensor_inplace:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], device='cuda:0')\n",
            "tensor_inplace after add_(5):\n",
            "tensor([[6., 6.],\n",
            "        [6., 6.]], device='cuda:0')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.4. Indexing and Slicing (similar to NumPy)\n",
        "print(\"4.4. Indexing and Slicing:\")\n",
        "indexing_tensor = torch.tensor([\n",
        "    [10, 11, 12, 13],\n",
        "    [20, 21, 22, 23],\n",
        "    [30, 31, 32, 33],\n",
        "    [40, 41, 42, 43]\n",
        "]).to(device)\n",
        "print(f\"Original indexing_tensor:\\n{indexing_tensor}\\n\")\n",
        "\n",
        "print(f\"First row: {indexing_tensor[0]}\")\n",
        "print(f\"Last column: {indexing_tensor[:, -1]}\")\n",
        "print(f\"Element at (1, 2): {indexing_tensor[1, 2]}\")\n",
        "print(f\"Sub-tensor (rows 0-1, cols 1-2):\\n{indexing_tensor[0:2, 1:3]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h801MIhH7IzG",
        "outputId": "f1caa36a-c316-4547-e3e9-af24204fc715"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.4. Indexing and Slicing:\n",
            "Original indexing_tensor:\n",
            "tensor([[10, 11, 12, 13],\n",
            "        [20, 21, 22, 23],\n",
            "        [30, 31, 32, 33],\n",
            "        [40, 41, 42, 43]], device='cuda:0')\n",
            "\n",
            "First row: tensor([10, 11, 12, 13], device='cuda:0')\n",
            "Last column: tensor([13, 23, 33, 43], device='cuda:0')\n",
            "Element at (1, 2): 22\n",
            "Sub-tensor (rows 0-1, cols 1-2):\n",
            "tensor([[11, 12],\n",
            "        [21, 22]], device='cuda:0')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.5. Reshaping and Squeezing/Unsqueezing\n",
        "print(\"4.5. Reshaping and Squeezing/Unsqueezing:\")\n",
        "x_reshape = torch.arange(9).to(device) # Creates a tensor [0, 1, ..., 8]\n",
        "print(f\"Original 1D tensor (arange(9)):\\n{x_reshape}\")\n",
        "print(f\"Shape: {x_reshape.shape}\")\n",
        "\n",
        "# Reshape to a 3x3 matrix\n",
        "x_reshaped = x_reshape.view(3, 3) # view() requires contiguous memory, reshape() is more flexible\n",
        "print(f\"Reshaped to 3x3:\\n{x_reshaped}\")\n",
        "print(f\"Shape: {x_reshaped.shape}\\n\")\n",
        "\n",
        "# Add a dimension (unsqueeze) - useful for batching or specific layer inputs\n",
        "x_unsqueeze = x_reshaped.unsqueeze(0) # Adds a dimension at position 0 (batch dimension)\n",
        "print(f\"Unsqueezed (adds a dim at 0):\\n{x_unsqueeze}\")\n",
        "print(f\"Shape after unsqueeze(0): {x_unsqueeze.shape}\\n\") # (1, 3, 3)\n",
        "\n",
        "# Remove a dimension of size 1 (squeeze)\n",
        "x_squeeze = x_unsqueeze.squeeze(0) # Removes the dimension at position 0 if its size is 1\n",
        "print(f\"Squeezed (removes dim at 0):\\n{x_squeeze}\")\n",
        "print(f\"Shape after squeeze(0): {x_squeeze.shape}\\n\") # (3, 3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azThrNR-7b4S",
        "outputId": "a8f6368b-30b6-4506-e322-d877882cdb79"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.5. Reshaping and Squeezing/Unsqueezing:\n",
            "Original 1D tensor (arange(9)):\n",
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8], device='cuda:0')\n",
            "Shape: torch.Size([9])\n",
            "Reshaped to 3x3:\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]], device='cuda:0')\n",
            "Shape: torch.Size([3, 3])\n",
            "\n",
            "Unsqueezed (adds a dim at 0):\n",
            "tensor([[[0, 1, 2],\n",
            "         [3, 4, 5],\n",
            "         [6, 7, 8]]], device='cuda:0')\n",
            "Shape after unsqueeze(0): torch.Size([1, 3, 3])\n",
            "\n",
            "Squeezed (removes dim at 0):\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]], device='cuda:0')\n",
            "Shape after squeeze(0): torch.Size([3, 3])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.6. Concatenation and Stacking\n",
        "print(\"4.6. Concatenation and Stacking:\")\n",
        "tensor1 = torch.ones(2, 2).to(device)\n",
        "tensor2 = torch.zeros(2, 2).to(device)\n",
        "print(f\"Tensor 1:\\n{tensor1}\")\n",
        "print(f\"Tensor 2:\\n{tensor2}\\n\")\n",
        "\n",
        "# Concatenate along dimension 0 (rows)\n",
        "concatenated_rows = torch.cat([tensor1, tensor2], dim=0)\n",
        "print(f\"Concatenated along dim 0 (rows):\\n{concatenated_rows}\")\n",
        "print(f\"Shape: {concatenated_rows.shape}\\n\") # (4, 2)\n",
        "\n",
        "# Concatenate along dimension 1 (columns)\n",
        "concatenated_cols = torch.cat([tensor1, tensor2], dim=1)\n",
        "print(f\"Concatenated along dim 1 (columns):\\n{concatenated_cols}\")\n",
        "print(f\"Shape: {concatenated_cols.shape}\\n\") # (2, 4)\n",
        "\n",
        "# Stacking creates a new dimension\n",
        "stacked_tensors = torch.stack([tensor1, tensor2], dim=0)\n",
        "print(f\"Stacked along dim 0:\\n{stacked_tensors}\")\n",
        "print(f\"Shape: {stacked_tensors.shape}\\n\") # (2, 2, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy3jHOSs7b_6",
        "outputId": "7e0935fc-36c5-4ed7-90fb-0e9bfe3640c8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.6. Concatenation and Stacking:\n",
            "Tensor 1:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.]], device='cuda:0')\n",
            "Tensor 2:\n",
            "tensor([[0., 0.],\n",
            "        [0., 0.]], device='cuda:0')\n",
            "\n",
            "Concatenated along dim 0 (rows):\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]], device='cuda:0')\n",
            "Shape: torch.Size([4, 2])\n",
            "\n",
            "Concatenated along dim 1 (columns):\n",
            "tensor([[1., 1., 0., 0.],\n",
            "        [1., 1., 0., 0.]], device='cuda:0')\n",
            "Shape: torch.Size([2, 4])\n",
            "\n",
            "Stacked along dim 0:\n",
            "tensor([[[1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[0., 0.],\n",
            "         [0., 0.]]], device='cuda:0')\n",
            "Shape: torch.Size([2, 2, 2])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- 5. Bridge with NumPy ---\")\n",
        "\n",
        "# 5.1. PyTorch Tensor to NumPy Array\n",
        "print(\"5.1. PyTorch Tensor to NumPy Array:\")\n",
        "torch_tensor = torch.ones(5).to(device) # Can be on CPU or GPU initially\n",
        "print(f\"PyTorch Tensor:\\n{torch_tensor}\")\n",
        "print(f\"Device of PyTorch Tensor: {torch_tensor.device}\")\n",
        "\n",
        "# If tensor is on GPU, it must be moved to CPU before converting to NumPy\n",
        "if torch_tensor.is_cuda:\n",
        "    numpy_array_from_torch = torch_tensor.cpu().numpy()\n",
        "else:\n",
        "    numpy_array_from_torch = torch_tensor.numpy()\n",
        "\n",
        "print(f\"NumPy Array from Tensor:\\n{numpy_array_from_torch}\")\n",
        "print(f\"Type of NumPy Array: {type(numpy_array_from_torch)}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gqm1-mvf7cGN",
        "outputId": "83b8a1fb-744f-44e3-f7f8-d92e1b009609"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 5. Bridge with NumPy ---\n",
            "5.1. PyTorch Tensor to NumPy Array:\n",
            "PyTorch Tensor:\n",
            "tensor([1., 1., 1., 1., 1.], device='cuda:0')\n",
            "Device of PyTorch Tensor: cuda:0\n",
            "NumPy Array from Tensor:\n",
            "[1. 1. 1. 1. 1.]\n",
            "Type of NumPy Array: <class 'numpy.ndarray'>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.2. NumPy Array to PyTorch Tensor\n",
        "print(\"5.2. NumPy Array to PyTorch Tensor:\")\n",
        "numpy_array = np.ones(5)\n",
        "torch_tensor_from_numpy = torch.from_numpy(numpy_array).to(device) # Move to device after creation\n",
        "print(f\"NumPy Array:\\n{numpy_array}\")\n",
        "print(f\"PyTorch Tensor from NumPy:\\n{torch_tensor_from_numpy}\")\n",
        "print(f\"Device of PyTorch Tensor from NumPy: {torch_tensor_from_numpy.device}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQLB9rGP7pAn",
        "outputId": "755d711b-c5e4-41cd-d0b8-8b3e23d8b1bc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.2. NumPy Array to PyTorch Tensor:\n",
            "NumPy Array:\n",
            "[1. 1. 1. 1. 1.]\n",
            "PyTorch Tensor from NumPy:\n",
            "tensor([1., 1., 1., 1., 1.], device='cuda:0', dtype=torch.float64)\n",
            "Device of PyTorch Tensor from NumPy: cuda:0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.3. Shared Memory between CPU Tensors and NumPy Arrays\n",
        "print(\"5.3. Shared Memory between CPU Tensors and NumPy Arrays:\")\n",
        "# IMPORTANT: This only happens when converting CPU tensors.\n",
        "# If a tensor is on GPU, it's copied to CPU first for conversion, breaking the shared memory.\n",
        "cpu_numpy_array = np.arange(5)\n",
        "cpu_torch_tensor = torch.from_numpy(cpu_numpy_array)\n",
        "\n",
        "print(f\"Original NumPy Array: {cpu_numpy_array}\")\n",
        "print(f\"Original PyTorch Tensor (from NumPy): {cpu_torch_tensor}\")\n",
        "\n",
        "# Modify the NumPy array\n",
        "cpu_numpy_array[0] = 99\n",
        "print(f\"NumPy Array after modification: {cpu_numpy_array}\")\n",
        "print(f\"PyTorch Tensor (observe change, as memory is shared): {cpu_torch_tensor}\\n\")\n",
        "\n",
        "# Modify the PyTorch tensor\n",
        "cpu_torch_tensor[1] = 88\n",
        "print(f\"PyTorch Tensor after modification: {cpu_torch_tensor}\")\n",
        "print(f\"NumPy Array (observe change, as memory is shared): {cpu_numpy_array}\\n\")\n",
        "\n",
        "# --- End of Notebook ---\n",
        "print(\"--- End of PyTorch Tensors Fundamentals Notebook ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQmHxdkk7vKL",
        "outputId": "abbc486a-047e-4e86-954f-c9b8cbf665fa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.3. Shared Memory between CPU Tensors and NumPy Arrays:\n",
            "Original NumPy Array: [0 1 2 3 4]\n",
            "Original PyTorch Tensor (from NumPy): tensor([0, 1, 2, 3, 4])\n",
            "NumPy Array after modification: [99  1  2  3  4]\n",
            "PyTorch Tensor (observe change, as memory is shared): tensor([99,  1,  2,  3,  4])\n",
            "\n",
            "PyTorch Tensor after modification: tensor([99, 88,  2,  3,  4])\n",
            "NumPy Array (observe change, as memory is shared): [99 88  2  3  4]\n",
            "\n",
            "--- End of PyTorch Tensors Fundamentals Notebook ---\n"
          ]
        }
      ]
    }
  ]
}